{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Abstractive Summarizer in CNN Daily Mail\n",
    "\n",
    "## Text Summarization\n",
    "\n",
    "![Text Summarization](https://blog.fpt-software.com/hs-fs/hubfs/image-8.png?width=376&name=image-8.png)\n",
    "\n",
    "Text summarization คือ กระบวนการที่ใช้ในการสรุปข้อความยาวๆ ให้เป็นข้อความขนาดสั้นๆ ที่เข้าใจได้ง่าย และยังคงไว้ซึ่งสารที่ต้องการสื่อ\n",
    "\n",
    "โดยทั่วไป การทำสรุปจะมีสองประเภท คือ การสรุปแบบ Extractive Summary และการสรุปแบบ Abstractive Summary\n",
    "\n",
    "โดย Extractive Summary จะเป็นการเลือกประโยคที่มีใจความเด่นๆ ขึ้นมาทำเป็นสรุป\n",
    "แต่ Abstractive Summary จะเป็นการเขียนข้อความขึ้นมาใหม่ให้สั้นและกระทัดรัด"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Abstractive Summarizer\n",
    "\n",
    "Bidirectional Encoder Representations from Transformers (BERT) คือ pre-trained language model ที่ไม่ยึดติดกับภาษาใดภาษาหนึ่ง ซึ่งสามารถนำไปใช้กับการประยุกต์ใช้การประมวลผลภาษาธรรมชาติต่างๆ เช่น ระบบตอบคำถาม หรือการทำสรุปใจความอัตโนมัติ ซึ่งถูกพัฒนาโดย Google และสามารถนำ pre-trained model ไปใช้ได้\n",
    "\n",
    "ในตัวอย่างนี้จะทำการ download pre-trained BERT model ซึ่งทำงานบน Tensorflow framework มาใช้โดยจะแสดงขั้นตอนต่างๆ ดังนี้\n",
    "\n",
    "1. Install and setup tools\n",
    "2. Load BERT Model\n",
    "3. Load CNN-Daily Mail data\n",
    "4. Setup tokenization pipeline\n",
    "5. Config Tensorflow session and Test prediction using BERT\n",
    "6. Visualize output\n",
    "\n",
    "![BERT High level architect](https://deeplearn.org/arxiv_files/1907.06226v2/MLM_LS.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Install tools\n",
    "\n",
    "[Attention Visualizer](https://github.com/abisee/attn_vis) เป็นเครื่องมือที่ใช้ในการแสดงผล highlight\n",
    "\n",
    "[BERT Abstractive Summary](https://github.com/raufer/bert-summarization) เป็น abstractive summarization ที่ทใช้ BERT เป็น pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/raufer/bert-summarization bert_sum 2>/dev/null\n",
    "!git clone https://github.com/abisee/attn_vis 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "\n",
    "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "from rouge import Rouge\n",
    "import numpy as np\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/ops/tokenization.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/ops/tokenization.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/venv/lib/python3.7/site-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/venv/lib/python3.7/site-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data.load import pipeline\n",
    "from ops.tokenization import tokenizer\n",
    "from ops.session import initialize_vars\n",
    "from ops.session import save_variable_specs\n",
    "from models.abstractive_summarizer import AbstractiveSummarization\n",
    "from models.abstractive_summarizer import eval\n",
    "from models.abstractive_summarizer import train\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO) \n",
    "tf.enable_resource_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Load BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracting pretrained word embeddings weights from BERT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/ops/session.py:11: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/ops/session.py:11: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/ops/session.py:12: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/ops/session.py:12: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/ops/session.py:13: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/ops/session.py:13: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/ops/session.py:14: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/ops/session.py:14: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/models/abstractive_summarizer.py:61: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/models/abstractive_summarizer.py:61: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "INFO:root:Embedding matrix shape '(30522, 768)'\n"
     ]
    }
   ],
   "source": [
    "model = AbstractiveSummarization(\n",
    "    num_layers=config.NUM_LAYERS,\n",
    "    d_model=config.D_MODEL,\n",
    "    num_heads=config.NUM_HEADS,\n",
    "    dff=config.D_FF,\n",
    "    vocab_size=config.VOCAB_SIZE,\n",
    "    input_seq_len=config.INPUT_SEQ_LEN,\n",
    "    output_seq_len=config.OUTPUT_SEQ_LEN,\n",
    "    rate=config.DROPOUT_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Load CNN-DailyMail dataset using Tensorflow Datasets\n",
    "\n",
    "ดลและทำการ split dataset เป็น train / test / validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:No config specified, defaulting to first: cnn_dailymail/plain_text\n",
      "WARNING:absl:Found a different version 3.0.0 of dataset cnn_dailymail in data_dir /home/rattaphon/tensorflow_datasets. Using currently defined version 0.0.2.\n",
      "INFO:absl:Overwrite dataset info from restored data version.\n",
      "INFO:absl:Reusing dataset cnn_dailymail (/home/rattaphon/tensorflow_datasets/cnn_dailymail/plain_text/0.0.2)\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('cnn_dailymail', with_info=True, as_supervised=True)\n",
    "\n",
    "train, val, test = examples['train'], examples['validation'], examples['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab information regarding the number of examples\n",
    "metadata = json.loads(metadata.as_json)\n",
    "\n",
    "n_test_examples = int(metadata['splits'][0]['statistics']['numExamples'])\n",
    "n_train_examples = int(metadata['splits'][1]['statistics']['numExamples'])\n",
    "n_val_examples = int(metadata['splits'][2]['statistics']['numExamples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'citation': '@article{DBLP:journals/corr/SeeLM17,\\n  author    = {Abigail See and\\n               Peter J. Liu and\\n               Christopher D. Manning},\\n  title     = {Get To The Point: Summarization with Pointer-Generator Networks},\\n  journal   = {CoRR},\\n  volume    = {abs/1704.04368},\\n  year      = {2017},\\n  url       = {http://arxiv.org/abs/1704.04368},\\n  archivePrefix = {arXiv},\\n  eprint    = {1704.04368},\\n  timestamp = {Mon, 13 Aug 2018 16:46:08 +0200},\\n  biburl    = {https://dblp.org/rec/bib/journals/corr/SeeLM17},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n\\n@inproceedings{hermann2015teaching,\\n  title={Teaching machines to read and comprehend},\\n  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},\\n  booktitle={Advances in neural information processing systems},\\n  pages={1693--1701},\\n  year={2015}\\n}\\n',\n",
       " 'description': 'CNN/DailyMail non-anonymized summarization dataset.\\n\\nThere are two features:\\n  - article: text of news article, used as the document to be summarized\\n  - highlights: joined text of highlights with <s> and </s> around each\\n    highlight, which is the target summary\\n',\n",
       " 'location': {'urls': ['https://github.com/abisee/cnn-dailymail']},\n",
       " 'name': 'cnn_dailymail',\n",
       " 'schema': {'feature': [{'name': 'article', 'type': 'BYTES'},\n",
       "   {'name': 'highlights', 'type': 'BYTES'}]},\n",
       " 'sizeInBytes': '585439472',\n",
       " 'splits': [{'name': 'test',\n",
       "   'numShards': '10',\n",
       "   'statistics': {'features': [{'bytesStats': {'commonStats': {'numNonMissing': '11490'}},\n",
       "      'name': 'article',\n",
       "      'type': 'BYTES'},\n",
       "     {'bytesStats': {'commonStats': {'numNonMissing': '11490'}},\n",
       "      'name': 'highlights',\n",
       "      'type': 'BYTES'}],\n",
       "    'numExamples': '11490'}},\n",
       "  {'name': 'train',\n",
       "   'numShards': '100',\n",
       "   'statistics': {'features': [{'bytesStats': {'commonStats': {'numNonMissing': '287113'}},\n",
       "      'name': 'article',\n",
       "      'type': 'BYTES'},\n",
       "     {'bytesStats': {'commonStats': {'numNonMissing': '287113'}},\n",
       "      'name': 'highlights',\n",
       "      'type': 'BYTES'}],\n",
       "    'numExamples': '287113'}},\n",
       "  {'name': 'validation',\n",
       "   'numShards': '10',\n",
       "   'statistics': {'features': [{'bytesStats': {'commonStats': {'numNonMissing': '13368'}},\n",
       "      'name': 'article',\n",
       "      'type': 'BYTES'},\n",
       "     {'bytesStats': {'commonStats': {'numNonMissing': '13368'}},\n",
       "      'name': 'highlights',\n",
       "      'type': 'BYTES'}],\n",
       "    'numExamples': '13368'}}],\n",
       " 'supervisedKeys': {'input': 'article', 'output': 'highlights'},\n",
       " 'version': '0.0.2'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Setup tokenization pipeline\n",
    "\n",
    "สำหรับการตัดคำ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pipeline(train, tokenizer)\n",
    "val_dataset = pipeline(val, tokenizer)\n",
    "test_dataset = pipeline(test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-91fd62485c73>:1: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-91fd62485c73>:1: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "val_iterator = val_dataset.make_initializable_iterator()\n",
    "train_iterator = train_dataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Config Tensorflow session and Test prediction using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทำการ setup Tensorflow graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Building Evaluation Graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Building: 'Greedy Draft Summary'\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/models/abstractive_summarizer.py:157: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/models/abstractive_summarizer.py:157: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      " 25%|██▌       | 1/4 [00:04<00:13,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:06<00:07,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:07<00:03,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Building: 'Greedy Refined Summary'\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:04<00:14,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:09<00:09,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:14<00:04,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:19<00:00,  4.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/models/abstractive_summarizer.py:545: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/models/abstractive_summarizer.py:545: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/ops/tokenization.py:49: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/ops/tokenization.py:49: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/models/abstractive_summarizer.py:553: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/models/abstractive_summarizer.py:553: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/models/abstractive_summarizer.py:557: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/models/abstractive_summarizer.py:557: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/models/abstractive_summarizer.py:566: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rattaphon/acaya/bert_sum/models/abstractive_summarizer.py:566: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# warm up tensorflow graph\n",
    "val_stream = val_iterator.get_next()\n",
    "xs, ys = val_stream[:3], val_stream[3:] \n",
    "y, y_hat, eval_loss, eval_summaries = eval(model, xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict โดยใช้ eval ซึ่งจะมีการทำการ decode (แปลง index token เป็น text token) มาให้พร้อมใช้งาน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint2/abstractive_summarization_2019_final-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint2/abstractive_summarization_2019_final-0\n",
      "INFO:root:Building Evaluation Graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Building: 'Greedy Draft Summary'\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:02<00:02,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 4/4 [00:05<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:root:Building: 'Greedy Refined Summary'\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f95e4919670>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:05<00:17,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:11<00:11,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:18<00:06,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:24<00:00,  6.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# Setting TF graph    \n",
    "saver = tf.train.Saver(max_to_keep=config.NUM_EPOCHS)\n",
    "config_tf = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    ckpt = tf.train.latest_checkpoint(config.CHECKPOINTDIR)\n",
    "\n",
    "    rouge = Rouge()\n",
    "\n",
    "    if ckpt is None:\n",
    "        logging.info(\"Initializing from scratch\")\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        save_variable_specs(os.path.join(config.LOGDIR, \"specs\"))\n",
    "    else:\n",
    "        saver.restore(sess, ckpt)   \n",
    "    \n",
    "    initialize_vars(sess)\n",
    "        \n",
    "    # fetch data\n",
    "    val_stream = val_iterator.get_next()\n",
    "    xs, ys = val_stream[:3], val_stream[3:] \n",
    "\n",
    "    # evaluate\n",
    "    y, y_hat, eval_loss, eval_summaries = eval(model, xs, ys)\n",
    "    \n",
    "    sess.run(val_iterator.initializer)\n",
    "    \n",
    "    _y, _y_hat = sess.run([y, y_hat])\n",
    "\n",
    "    # decode id to tokens and article\n",
    "    y_str = ' '.join(tokenizer.convert_ids_to_tokens(list(_y[0])))\n",
    "    y_hat_str = ' '.join(tokenizer.convert_ids_to_tokens(list(_y_hat[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ใช้ model.predict เพื่อดึงค่า attention distribution ไปใช้งานต่อ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data\n",
    "val_stream = val_iterator.get_next()\n",
    "xs, ys = val_stream[:3], val_stream[3:] \n",
    "\n",
    "# logits_draft_summary, preds_draft_summary, draft_attention_dist, logits_refined_summary, preds_refined_summary, refined_attention_dist = model.predict(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:root:Building: 'Greedy Draft Summary'\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:03<00:03,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.65s/it]\n",
      "INFO:root:Building: 'Greedy Refined Summary'\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:07<00:21,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:14<00:14,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:22<00:07,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Decoder.call of <layers.transformer.Decoder object at 0x7f9528479890>>, which Python reported as:\n",
      "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
      "        \n",
      "        seq_len = tf.shape(x)[1]\n",
      "        attention_weights = {}\n",
      "\n",
      "#         if not input_alreay_embedded:\n",
      "#             x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
      "            \n",
      "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
      "        x += self.pos_encoding[:, :seq_len, :]\n",
      "\n",
      "        x = self.dropout(x, training=training)\n",
      "\n",
      "        for i in range(self.num_layers):\n",
      "            \n",
      "#             dv = f\"/device:GPU:{str(next(selector))}\"\n",
      "#             print(f\"With device )\n",
      "#             with tf.device():\n",
      "                \n",
      "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
      "\n",
      "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
      "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
      "\n",
      "        # x.shape == (batch_size, target_seq_len, d_model)\n",
      "        return x, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# warm up tensorflow graph\n",
    "saver = tf.train.Saver(max_to_keep=config.NUM_EPOCHS)\n",
    "config_tf = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    initialize_vars(sess)\n",
    "        \n",
    "    # fetch data\n",
    "    val_stream = val_iterator.get_next()\n",
    "    xs, ys = val_stream[:3], val_stream[3:] \n",
    "\n",
    "    # evaluate\n",
    "    logits_draft_summary, preds_draft_summary, draft_attention_dist, logits_refined_summary, preds_refined_summary, refined_attention_dist = model.predict(xs)\n",
    "    \n",
    "    sess.run(val_iterator.initializer)\n",
    "    \n",
    "    _logits_draft_summary, _logits_refined_summary, _refined_attention_dist = sess.run([logits_draft_summary, logits_refined_summary, refined_attention_dist])\n",
    "    attention_dist = _refined_attention_dist[-1][\"decoder_layer8_block2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_lst = tokenizer.convert_ids_to_tokens(list(_y_hat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_dist = _refined_attention_dist[-1][\"decoder_layer8_block2\"].squeeze(axis=0).squeeze(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_viz_json = {\n",
    "    \"article_lst\": \"\", # Xs\n",
    "    \"p_gens\": [[x*0.0] for x in range(len(y_hat_lst))], # BERT did not directly emit them\n",
    "    \"decoded_lst\": y_hat_lst,\n",
    "    \"abstract_str\": y_str, \n",
    "    \"attn_dists\": attention_dist.tolist()\n",
    "}\n",
    "with open('./attn_vis/attn_vis_data.json', 'w') as outfile:\n",
    "    json.dump(att_viz_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'prevalent', 'grinned', 'prevalent', 'prevalent']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src='http://localhost:8000', width=900, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rnd = convert_idx_to_token_tensor(xs[0][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
